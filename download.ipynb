{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import boto3\n",
    "import os\n",
    "import errno\n",
    "from utils import *\n",
    "\n",
    "\n",
    "def save_obj(obj, path, name):\n",
    "    \"\"\" Save an object into a pickle file. \"\"\"\n",
    "    with open(path + name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def load_obj(path, name):\n",
    "    \"\"\" Load a pickle file into an object. \"\"\"\n",
    "    with open(path + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "def create_directory(directory):\n",
    "    \"\"\" Create a directory if it does not exist and return the directory. \"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        try:\n",
    "            os.makedirs(directory)\n",
    "        except OSError as e:\n",
    "            if e.errno != errno.EEXIST:\n",
    "                raise\n",
    "    return directory\n",
    "\n",
    "\n",
    "def write_image_into_file(key, file_name, file_directory):\n",
    "    \"\"\" Write images into directory. \"\"\"\n",
    "    file_directory = create_directory(file_directory)\n",
    "    session = boto3.session.Session()\n",
    "    try:\n",
    "        obj = session.resource('s3').Bucket('root-image-uploads').Object(key=key).get()['Body'].read()\n",
    "        with open(file_directory + file_name + '.jpg', 'wb') as f:\n",
    "            f.write(obj)\n",
    "    except session.resource('s3').meta.client.exceptions.NoSuchKey:\n",
    "        print(\"no such key in bucket\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def download_images_from_s3_bucket(df_image, file_directory, total_images=100):\n",
    "    \"\"\" download images from S3 bucket. \"\"\"\n",
    "    image_count = 0\n",
    "    for key, image_id in zip(df_image['s3_file_path'], df_image['img_id']):\n",
    "        if image_count >= total_images:\n",
    "            break\n",
    "        else:\n",
    "            image_count += 1\n",
    "        write_image_into_file(key, image_id, file_directory)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: root_image: File exists\n",
      "mkdir: root_image/damage_angle: File exists\n",
      "mkdir: root_image/damage_in_context: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir root_image\n",
    "!mkdir root_image/damage_angle\n",
    "!mkdir root_image/damage_in_context\n",
    "!mkdir root_image/damage_close_up\n",
    "!mkdir root_image/back_passenger_side\n",
    "!mkdir root_image/front_passenger_side\n",
    "!mkdir root_image/back_driver_side\n",
    "!mkdir root_image/front_driver_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = db_connection()\n",
    "con.autocommit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = '''\n",
    "with claim_payment as (\n",
    "select\n",
    "    dc.claim_id,\n",
    "    sum(paid_loss_dollar_amount) as paid,\n",
    "    sum(reserved_dollar_amount) as reserved\n",
    "from edw.dim_claim dc\n",
    "join edw.fact_financials_accumulating ffa on ffa.claim_k = dc.claim_k\n",
    "join edw.dim_coverage cov on ffa.coverage_k = cov.coverage_k\n",
    "where development_age_in_months = 4 and cov.symbol in ('pd', 'col', 'comp')\n",
    "group by 1\n",
    ")\n",
    "select \n",
    "    c.id as claim_id,\n",
    "    img.id as img_id,\n",
    "    img.s3_file_path,\n",
    "    fnol.label,\n",
    "    fnol.source,\n",
    "    pay.paid\n",
    "from server_public.first_notice_of_loss_photos fnol\n",
    "join server_public.image_uploads img on img.id = fnol.image_upload_id\n",
    "join server_public.claims c on c.first_notice_of_loss_id = fnol.first_notice_of_loss_id\n",
    "join claim_payment pay on c.id = pay.claim_id\n",
    "'''\n",
    "\n",
    "df = pd.read_sql(sql_query, con)\n",
    "df.to_pickle(\"paid_claim_fnol_images.pkl.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "damage_angle (5511, 6)\n",
      "back_passenger_side (5583, 6)\n",
      "front_passenger_side (6181, 6)\n",
      "mileage (5186, 6)\n",
      "damage_in_context (5536, 6)\n",
      "damage_close_up (6288, 6)\n",
      "back_driver_side (5505, 6)\n",
      "front_driver_side (6381, 6)\n"
     ]
    }
   ],
   "source": [
    "for label in ('damage_angle', 'back_passenger_side',\n",
    "       'front_passenger_side', 'mileage', 'damage_in_context',\n",
    "       'damage_close_up', 'back_driver_side', 'front_driver_side'):\n",
    "\n",
    "    data = df[(df['label']==label)]\n",
    "    print(label, data.shape)\n",
    "    download_images_from_s3_bucket(data, 'root_image/'+label+'/', total_images=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "def download(url):\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    if not os.path.exists(filename):\n",
    "        urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "# Tool for creating lst file\n",
    "download('https://raw.githubusercontent.com/apache/incubator-mxnet/master/tools/im2rec.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
